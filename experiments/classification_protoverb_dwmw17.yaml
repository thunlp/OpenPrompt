dataset:
  name: dwmw17
  path: datasets/TextClassification/dwmw17

plm:
  model_name: roberta
  model_path: roberta-large
  optimize:
    freeze_para: False
    lr: 0.00003
    weight_decay: 0.01
    scheduler:
      type: 
      num_warmup_steps: 500

checkpoint:
  save_latest: False
  save_best: False

train:
  batch_size: 2
  num_epochs: 5
  train_verblizer: post
  clean: True

test:
  batch_size: 2

template: manual_template
verbalizer: proto_verbalizer

manual_template:
  choice: 0
  file_path: scripts/TextClassification/dwmw17/manual_template.txt

proto_verbalizer:
  parent_config: dwmw17
  choice: 0
  file_path: scripts/TextClassification/dwmw17/icl_verbalizer.json
  lr: 0.01
  mid_dim: 128
  epochs: 30
  multi_verb: multi

  

environment:
  num_gpus: 1
  cuda_visible_devices:
    - 0
  local_rank: 0
  
learning_setting: few_shot

few_shot:
  parent_config: learning_setting
  few_shot_sampling: sampling_from_train
  
sampling_from_train:
  parent_config: few_shot_sampling
  num_examples_per_label: 1
  also_sample_dev: True
  num_examples_per_label_dev: 1
  seed:
    - 123

reproduce:  # seed for reproduction 
  seed: 123  # a seed for all random part